{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "-------\n",
    "# XArray 101 üåç  \n",
    "-------\n",
    "* Jupyter and Python Basics\n",
    "* __Xarray Intro__\n",
    "* Xarray Advanced\n",
    "* Vector Data\n",
    "* Remote Sensing\n",
    "* Visualization\n",
    "\n",
    "-------  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with gridded data: xarray\n",
    "\n",
    "![xarray](http://xarray.pydata.org/en/stable/_static/dataset-diagram-logo.png)\n",
    "\n",
    "\n",
    "\n",
    "[Xarray](http://xarray.pydata.org/en/stable/) is one of the great packages to know if you work with any gridded data. \n",
    "\n",
    "To cite from their homepage:\n",
    "\n",
    ">Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw [NumPy](http://www.numpy.org/)-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. The package includes a large and growing library of domain-agnostic functions for advanced analytics and visualization with these data structures.\n",
    ">\n",
    ">Xarray was inspired by and borrows heavily from [pandas](http://pandas.pydata.org/), the popular data analysis package focused on labelled tabular data. It is particularly tailored to working with [netCDF](http://www.unidata.ucar.edu/software/netcdf) files, which were the source of xarray‚Äôs data model, and integrates tightly with [dask](http://dask.org/) for parallel computing.\n",
    "\n",
    "This is great since we know that all things numpy are fast, pandas at the center of Python Data Science anyways since it's so friendly, powerful and flexible. Furthermore, netCDF is a really good data format to use since it encapsulates not only potentially multiple variables, but also meta-data and units and is very widely used in sciences and in the industry. And finally, dask is really great if you have to work with large and potentially distributed data. We will have a quick look at dask later in the course. For now it's good to know that xarray will automatically utilize it if it's installed.\n",
    "\n",
    "Let's get a quick overview:\n",
    "\n",
    "## Basics\n",
    "\n",
    "Xarray has two core data structures, which build upon and extend the core strengths of NumPy and pandas. Both are fundamentally N-dimensional:\n",
    "\n",
    "- **DataArray** is a labeled, N-dimensional array. It is an N-D generalization of a pandas.Series.\n",
    "- **Dataset** is a multi-dimensional, in-memory array database. It is a dict-like container of DataArray objects aligned along any number of shared dimensions, and serves a similar purpose in xarray to the pandas.DataFrame.\n",
    "\n",
    "The value of attaching labels to numpy‚Äôs numpy.ndarray may be fairly obvious, but the dataset may need more motivation. The dataset data model is borrowed from the netCDF file format, which also provides xarray with a natural and portable serialization format. NetCDF is very popular in the geosciences, and there are existing libraries for reading and writing netCDF in many programming languages, including Python.\n",
    "\n",
    "Let's start with some [very basic examples](http://xarray.pydata.org/en/stable/quick-overview.html) to see it in action. We then proceed to a more realsistic example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a dataarray with 2 dimensions (named x and y) and the coordinate labels 10 and 20 for the x dimensions\n",
    "data = xr.DataArray(np.random.randn(2, 3), dims=('x', 'y'), coords={'x': [10, 20]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like in pandas, values is a numpy array that you can modify in-place\n",
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can store additional meta-data in the `attrs` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Like in numpy and pandas, indexing can get pretty complex but is really powerful. This only shows you the very basics. You probably want to read up on it [here](http://xarray.pydata.org/en/stable/indexing.html#indexing).\n",
    "\n",
    "However, in xarray, there are 4 ways of doing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional and by integer label, like numpy\n",
    "data[[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional and by coordinate label, like pandas\n",
    "data.loc[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by dimension name and integer label\n",
    "data.isel(x=slice(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by dimension name and coordinate label\n",
    "data.sel(x=[10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes/ Meta-data\n",
    "\n",
    "It‚Äôs often a good idea to set metadata attributes. A useful choice is to set data.attrs['long_name'] and data.attrs['units'] since xarray will use these, if present, to automatically label your plots. These special names were chosen following the [NetCDF Climate and Forecast (CF) Metadata Conventions](http://cfconventions.org/cf-conventions/cf-conventions.html). `attrs` is just a Python dictionary, so you can assign anything you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning attributes to dataarray\n",
    "data.attrs['long_name'] = 'random velocity'\n",
    "data.attrs['units'] = 'metres/sec'\n",
    "data.attrs['description'] = 'A random variable created as an example.'\n",
    "data.attrs['random_attribute'] = 123\n",
    "data.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation\n",
    "\n",
    "Another great feature is that dataarrays work similar to numpy ndarrays. Observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, aggregation operations can use dimension names instead of axis numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the mean over the x-dimension\n",
    "data.mean(dim='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy\n",
    "\n",
    "Like pandas, xarray supports `groupby` operations (see: [here](http://xarray.pydata.org/en/stable/groupby.html#groupby))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = xr.DataArray(['E', 'F', 'E'], [data.coords['y']], name='labels')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean of y over the labels\n",
    "data.groupby(labels).mean('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "You can directly plot on xarray objects (like with pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "**xr.Dataset** is a dict-like container of aligned DataArray objects. You can think of it as a multi-dimensional generalization of the **pd.DataFrame**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset({'foo': data, 'bar': ('x', [1, 2]), 'baz': np.pi})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the individual variables/ dataarrays of a dataset like with a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['foo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read/ write netCDF files\n",
    "\n",
    "NetCDF is the recommended file format for xarray objects. Users from the geosciences will recognize that the Dataset data model looks very similar to a netCDF file (which, in fact, inspired it).\n",
    "You can directly read and write xarray objects to disk using `to_netcdf()`, `open_dataset()` and `open_dataarray()`.\n",
    "\n",
    "Later, we will also use another vaariant. As it is common for datasets to be distributed across multiple files (commonly one file per timestep) xarray supports this use-case by providing the `open_mfdataset()` and the `save_mfdataset()` methods. For more, see [Reading and writing files](http://xarray.pydata.org/en/stable/io.html#io) or later notebooks in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf('example.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = xr.open_dataset('example.nc')\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "! rm example.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open multiple files as one\n",
    "\n",
    "The following example is from: https://rabernat.github.io/research_computing_2018/xarray-tips-and-tricks.html\n",
    "\n",
    "One thing we love about xarray is the `open_mfdataset()` function, which combines many netCDF files into a single xarray Dataset.\n",
    "But what if the files are stored on a remote server and accessed over OpenDAP. An example can be found in NOAA's NCEP Reanalysis catalog.\n",
    "\n",
    "https://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/ncep.reanalysis/surface/catalog.html\n",
    "\n",
    "The dataset is split into different files for each variable and year. For example, a single file for surface air temperature looks like:\n",
    "\n",
    "http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.reanalysis/surface/air.sig995.1948.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset split into different files\n",
    "base_url = 'http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/ncep.reanalysis/surface/air.sig995'\n",
    "files = [f'{base_url}.{year}.nc' for year in range(1948, 2019)]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can open them as if they were a single file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might fail due to network\n",
    "ds = xr.open_mfdataset(files[-10:])\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can operate on them (like selecting a region), too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dseu = ds.sel(lat=slice(60,20), lon=slice(0,30))\n",
    "\n",
    "ts = dseu.mean(dim=['lat','lon'])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.air.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some actual Analysis: SST example\n",
    "\n",
    "Example from: https://rabernat.github.io/research_computing_2018/intermediate-xarray.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to use interactive plotting with hvplot\n",
    "import holoviews as hv\n",
    "from holoviews.streams import Params\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file from this address... \n",
    "! wget http://ldeo.columbia.edu/~rpa/NOAA_NCDC_ERSST_v3b_SST.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('NOAA_NCDC_ERSST_v3b_SST.nc')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the longitudes are organized from 0 - 360 (US style). We can change this easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to -180/180\n",
    "ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "ds = ds.sortby(ds.lon)\n",
    "\n",
    "sst = ds.sst\n",
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also operate over the dimensions. In the following cell we group by months, and compute the mean over the time dimensions creating a monthly climatology. The we compute the anomaly of each month in the original time-series to this climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by time axis - take the mean of the grouped batches over the time dim\n",
    "sst_clim = sst.groupby('time.month').mean(dim='time')\n",
    "# substract the climatology from the months of every year\n",
    "sst_anom = sst.groupby('time.month') - sst_clim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we `groupby` in hvplot we get a slider where we can interact with the plot with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_anom.hvplot('lon','lat',groupby='time', width=600, cmap='RdBu', clim=(-2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a point in the dataset. You do not have to specify the exact matching grid cell - use `nearest` instead..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_ref = sst_anom.sel(lon=-160, lat=0, method='nearest')\n",
    "sst_ref.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, y, dims=None):\n",
    "    return xr.dot(x - x.mean(dims), y - y.mean(dims), dims=dims) / x.count(dims)\n",
    "\n",
    "def correlation(x, y, dims=None):\n",
    "    return covariance(x, y, dims) / (x.std(dims) * y.std(dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then do some computations between the point and the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_cor = correlation(sst_anom, sst_ref, dims='time')\n",
    "pc = sst_cor.plot()\n",
    "pc.axes.set_title('Correlation btw. global SST Anomaly and SST Anomaly at one point');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarray-101",
   "language": "python",
   "name": "xarray-101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
